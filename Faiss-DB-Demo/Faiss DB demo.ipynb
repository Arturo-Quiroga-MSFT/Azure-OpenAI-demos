{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af47bb13",
   "metadata": {},
   "source": [
    "# Faiss DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fbe299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dd67301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open AI version: 0.27.9\n",
      "langchain version: 0.0.278\n"
     ]
    }
   ],
   "source": [
    "print('Open AI version:', openai.__version__)\n",
    "print('langchain version:', langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe67b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables (set OPENAI_API_KEY, OPENAI_API_BASE, and OPENAI_API_VERSION in .env)\n",
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "# Configure OpenAI API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv('OPENAI_API_BASE')\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_version = os.getenv('OPENAI_API_VERSION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8477c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize gpt-35-turbo and our embedding model\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-35-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02a838d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002',\n",
    "                              deployment='text-embedding-ada-002',\n",
    "                              openai_api_base=openai.api_base,\n",
    "                              openai_api_type='azure',\n",
    "                              openai_api_key=openai.api_key,\n",
    "                              chunk_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d14b1d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AzureChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.7, model_kwargs={}, openai_api_key='8d0786663aa1480f9dee3c9edd842b1a', openai_api_base='https://azure-openai-serge.openai.azure.com', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None, deployment_name='gpt-35-turbo', model_version='', openai_api_type='azure', openai_api_version='2023-05-15')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94979b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='2023-05-15', openai_api_base='https://azure-openai-serge.openai.azure.com', openai_api_type='azure', openai_proxy='', embedding_ctx_length=8191, openai_api_key='8d0786663aa1480f9dee3c9edd842b1a', openai_organization='', allowed_special=set(), disallowed_special='all', chunk_size=1, max_retries=6, request_timeout=None, headers=None, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aaffb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('docs/',\n",
    "                         glob=\"*.txt\",\n",
    "                         loader_cls=TextLoader,\n",
    "                         loader_kwargs={'autodetect_encoding': True})\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "079fa7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.faiss.FAISS at 0x7f04eca25a50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = FAISS.from_documents(documents=docs, embedding=embeddings)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d3dacbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt if needed\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(\"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\")\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(llm=llm,\n",
    "                                           retriever=db.as_retriever(),\n",
    "                                           condense_question_prompt=CONDENSE_QUESTION_PROMPT,\n",
    "                                           return_source_documents=True,\n",
    "                                           verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df47e2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is Azure OpenAI Service?\n",
      "\n",
      "Answer: Azure OpenAI is a service that provides REST API access to OpenAI's language models such as GPT-3, Codex and Embeddings model series. Users can adapt the models to their specific task including content generation, summarization, semantic search, and natural language to code translation. The service can be accessed through REST APIs, Python SDK, or a web-based interface in the Azure OpenAI Studio. Azure OpenAI offers virtual network support, managed identity, and responsible AI content filtering. Access to the service is currently limited, but you can apply for initial access or for a production review.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "query = \"what is Azure OpenAI Service?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "\n",
    "print(\"Question:\", query)\n",
    "print(\"\\nAnswer:\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21db7bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which regions does the service support?\n",
      "\n",
      "Answer: Azure OpenAI Service is currently available in three regions: East US, South Central US, and West Europe.\n"
     ]
    }
   ],
   "source": [
    "chat_history = [(query, result[\"answer\"])]\n",
    "\n",
    "query = \"Which regions does the service support?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "\n",
    "print(\"Question:\", query)\n",
    "print(\"\\nAnswer:\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "990730fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is it available for East US?\n",
      "\n",
      "Answer: The Azure OpenAI Service is currently available in East US, South Central US, and West Europe.\n"
     ]
    }
   ],
   "source": [
    "chat_history = [(query, result[\"answer\"])]\n",
    "\n",
    "query = \"Is it available for East US?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "\n",
    "print(\"Question:\", query)\n",
    "print(\"\\nAnswer:\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876ff9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
