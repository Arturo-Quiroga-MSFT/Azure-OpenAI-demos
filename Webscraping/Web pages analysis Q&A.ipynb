{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b54dfc5b",
   "metadata": {},
   "source": [
    "# Web pages analysis Q&A with Azure Open AI and Azure Cognitive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96b1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import openai\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import AzureCognitiveSearchRetriever\n",
    "from langchain.vectorstores import AzureSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6efcce6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.10 (main, Mar 21 2023, 18:45:11) [GCC 11.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f9ab594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 23-Oct-2023 09:35:30\n"
     ]
    }
   ],
   "source": [
    "print(f\"Today is {datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d39276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open AI version: 0.28.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Open AI version:\", openai.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0e03c7",
   "metadata": {},
   "source": [
    "## Web pages analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab90ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://learn.microsoft.com/en-us/azure/ai-services/openai/faq\",\n",
    "    \"https://learn.microsoft.com/en-us/azure/ai-services/openai/overview\",\n",
    "    \"https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits\",\n",
    "    \"https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\",\n",
    "    \"https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/legacy-models\",\n",
    "    \"https://learn.microsoft.com/en-us/azure/ai-services/openai/whats-new\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d83a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"txt\"\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3524edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(urls)):\n",
    "    response = requests.get(urls[i])\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        # Extract all the text content from the HTML\n",
    "        text = soup.get_text()\n",
    "        text = text.replace(\"\\n\", \"\").replace(\"\\r\", \"\").replace(\"\\t\", \"\")\n",
    "        # Saving the extracted text as a text file\n",
    "        text_file = os.path.join(DATA_DIR, urls[i].split(\"/\")[-1] + \".txt\")\n",
    "        with open(text_file, \"w\") as file:\n",
    "            file.write(text)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the web page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90d21a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root  41K Oct 23 09:35 txt/faq.txt\r\n",
      "-rwxrwxrwx 1 root root 6.4K Oct 23 09:35 txt/legacy-models.txt\r\n",
      "-rwxrwxrwx 1 root root 9.4K Oct 23 09:35 txt/models.txt\r\n",
      "-rwxrwxrwx 1 root root 7.5K Oct 23 09:35 txt/overview.txt\r\n",
      "-rwxrwxrwx 1 root root 5.3K Oct 23 09:35 txt/quotas-limits.txt\r\n",
      "-rwxrwxrwx 1 root root  13K Oct 23 09:35 txt/whats-new.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls $DATA_DIR/*.txt -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cea8c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file {file}\n",
      "Processing file {file}\n",
      "Processing file {file}\n",
      "Processing file {file}\n",
      "Processing file {file}\n",
      "Processing file {file}\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "\n",
    "for file in [f for f in os.listdir(DATA_DIR) if f.endswith(\".txt\")]:\n",
    "    print(\"Processing file {file}\")\n",
    "    try:\n",
    "        loader = TextLoader(os.path.join(DATA_DIR, file), encoding=\"utf-8\")\n",
    "        docs.extend(loader.load_and_split())\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8dccea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7bfbe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"web-crawlerdemo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10ebca75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"azure.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3471ed1",
   "metadata": {},
   "source": [
    "## Azure Cognitive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c5780c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our embedding model\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    deployment=os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\"),\n",
    "    model=os.getenv(\"OPENAI_ADA_EMBEDDING_MODEL_NAME\"),\n",
    "    openai_api_base=os.getenv(\"OPENAI_API_BASE\"),\n",
    "    openai_api_type=\"azure\",\n",
    "    chunk_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b1b2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our Azure Search\n",
    "acs = AzureSearch(\n",
    "    azure_search_endpoint=os.getenv(\"AZURE_COGNITIVE_SEARCH_ENDPOINT\"),\n",
    "    azure_search_key=os.getenv(\"AZURE_COGNITIVE_SEARCH_API_KEY\"),\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab37b222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NDcyMDFlZmEtZmZjZC00YWU4LWFjNDItOWJiNzMwOGI1ZTM1',\n",
       " 'MzIwNGQyMWItNjRmZS00MWNkLTg3ZTYtNDIyZmE4NTJhNjJj',\n",
       " 'NDUxZmRiM2EtMWI1Ni00YzQ4LWJhN2EtMTViOTExNTUwZGQy',\n",
       " 'NThiMzcxYTAtMWYxOS00ZWNmLWJiMDYtM2FjZDU2YjA3YWIy',\n",
       " 'N2ZiODRjN2ItNmZmNy00MTExLWIyMTQtYzNlYTY5ZDg4NWI1',\n",
       " 'ZDI4YzhhZWEtYWYyYS00NjljLThlNjEtMTQ0OGZhNGEyYTBi',\n",
       " 'NDA3ODczMTQtODg2OC00ZTQ1LTg1MmMtZWY0NDZjNzM2ZmI5',\n",
       " 'MzA0YmYzYjEtNDQxNi00NWY4LWE1NDAtOTQ1NTZmYmZhNzFj',\n",
       " 'NDkyMDFiZWYtZjk5ZC00MDFkLWFkYjUtZDUzYWVjMTkyMDRj',\n",
       " 'ZWQ5MzFmMTYtZTlhNi00M2Q2LWE3NTYtNmU5MzM0YzkyNDA2',\n",
       " 'YjRiN2Q4OGUtODY0OS00OWJjLTg5YmEtOWE3MjJmMDNlNWY5',\n",
       " 'YTZiYWUwYzctYmNiOC00ZDdkLTljZWEtNTJlZmJiMjNmNmY0',\n",
       " 'NjZiZTNiYmYtYTRkMS00MjhmLWJhOTgtZjQxODg1MDRkZTU4',\n",
       " 'MmEyNDIyNWUtNDZlMC00Y2FkLTg4NzUtY2VhNWVmNTdjYmU2',\n",
       " 'N2M0OWY5YmYtYmY5Zi00YWMyLThkNWYtMmEyMzI4Zjg2ODZj',\n",
       " 'OTViZDUyMzctZGRmNC00Nzg2LThmYzktM2M1N2RjNjUzYzNm',\n",
       " 'ODZkY2JmMmEtMDEwZC00MjY4LWI1ZjYtYTFmMTlkNzcyYzky',\n",
       " 'NGEwODczMzctZGI5YS00NzUxLTkyZTgtMjI1ZjBiOWJhMjdk',\n",
       " 'NDBjZDAwYmMtYjFiNi00MGI4LThiN2MtMmExYTg1MDI3ODA4',\n",
       " 'OGQxZWI4ODAtZmFjMC00OTMxLTliYzQtMWU2YWEwMzAzNDY5',\n",
       " 'MjZmMWRjNjMtYTk3Zi00Y2U3LTk3NTUtOTEyMWY2ZTE4Y2Fh',\n",
       " 'Mjk2YjgxZTAtMzQ1MS00OTQ5LTgzYTEtYmFhNWFjMjFhYzEx',\n",
       " 'ODkyMGU5NzItNDczMy00NThkLWIzOWEtZGYwMjI4N2EzNDU2',\n",
       " 'ZDU3YWU5YjgtN2ZjMS00NzBkLTlhOTMtZTFkYmU1OGYwZGJm']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add documents to Azure Search\n",
    "acs.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28afc4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Azure Cognitive Search as our retriever\n",
    "retriever = AzureCognitiveSearchRetriever(\n",
    "    content_key=\"content\", top_k=5, index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "950629e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set chatGPT 3.5 as our LLM\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-35-turbo-16k\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7fd5b7",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2848f354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a template message\n",
    "template = \"\"\"\n",
    "You are an AI expert powered by Azure Open AI.\n",
    "You are going to analyse some text documents about Azure Open AI.\n",
    "If you do not know just say you do not know.\n",
    "Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "# Set the Retrieval QA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dd20ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa():\n",
    "    \"\"\"\n",
    "    Get answer\n",
    "    \"\"\"\n",
    "    result = qa_chain({\"query\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result))\n",
    "    source = result[\"source_documents\"][0].metadata[\"metadata\"]\n",
    "\n",
    "    print(f\"Question: {question} \\n\")\n",
    "    print(f\"Answer: {result['result']} \\n\")\n",
    "    print(f\"{source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe78f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2343bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who are you? \n",
      "\n",
      "Answer: I am an AI expert powered by Azure Open AI. I am here to provide information and answer questions about Azure Open AI. Thanks for asking! \n",
      "\n",
      "{\"source\": \"txt/faq.txt\"}\n"
     ]
    }
   ],
   "source": [
    "question = \"Who are you?\"\n",
    "\n",
    "res = qa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1352e41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is it possible to use GPT4? \n",
      "\n",
      "Answer: Yes, Azure OpenAI supports the latest GPT-4 models. It supports both GPT-4 and GPT-4-32K. Thanks for asking! \n",
      "\n",
      "{\"source\": \"txt/faq.txt\"}\n"
     ]
    }
   ],
   "source": [
    "question = \"Is it possible to use GPT4?\"\n",
    "\n",
    "qa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ab78382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How about GPT5? \n",
      "\n",
      "Answer: I'm sorry, but I do not have information about GPT-5. Thanks for asking! \n",
      "\n",
      "{\"source\": \"txt/faq.txt\"}\n"
     ]
    }
   ],
   "source": [
    "question = \"How about GPT5?\"\n",
    "\n",
    "qa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f6d5ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How about the quotas? \n",
      "\n",
      "Answer: The quotas and limits for Azure OpenAI are subject to change, but here are some of the default quotas and limits:\n",
      "\n",
      "- OpenAI resources per region per Azure subscription: 30\n",
      "- Default DALL-E quota limits: 2 concurrent requests\n",
      "- Maximum prompt tokens per request: Varies per model\n",
      "- Max fine-tuned model deployments: 2\n",
      "- Total number of training jobs per resource: 100\n",
      "- Max simultaneous running training jobs per resource: 1\n",
      "- Max training jobs queued: 20\n",
      "- Max Files per resource: 30\n",
      "- Total size of all files per resource: 1 GB\n",
      "- Max training job time: 720 hours\n",
      "- Max training job size: 2 Billion tokens in training file\n",
      "- Max size of all files per upload (Azure OpenAI on your data): 16 MB\n",
      "\n",
      "Please note that these are just some of the quotas and limits, and there may be additional limits depending on the specific model and region. It's always a good idea to check the official documentation for the most up-to-date information on quotas and limits.\n",
      "\n",
      "Thanks for asking! \n",
      "\n",
      "{\"source\": \"txt/quotas-limits.txt\"}\n"
     ]
    }
   ],
   "source": [
    "question = \"How about the quotas?\"\n",
    "\n",
    "qa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0c8f13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the tokens per minutes quota for gpt-35-turbo? \n",
      "\n",
      "Answer: The tokens per minute quota for gpt-35-turbo varies depending on the region. In regions such as East US, South Central US, West Europe, France Central, UK South, the quota is 240K tokens per minute. In regions like North Central US, Australia East, East US 2, Canada East, Japan East, Sweden Central, Switzerland North, the quota is 300K tokens per minute. Thanks for asking! \n",
      "\n",
      "{\"source\": \"txt/whats-new.txt\"}\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the tokens per minutes quota for gpt-35-turbo?\"\n",
    "\n",
    "qa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5c31d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How to do quota increase request? \n",
      "\n",
      "Answer: To request a quota increase, you can submit a request from the Quotas page of Azure OpenAI Studio. However, please note that due to overwhelming demand, quota increase requests are being accepted and filled in the order they are received. Priority is given to customers who generate traffic that consumes the existing quota allocation, and your request may be denied if this condition is not met. For other rate limits, you can submit a service request. Thanks for asking! \n",
      "\n",
      "{\"source\": \"txt/quotas-limits.txt\"}\n"
     ]
    }
   ],
   "source": [
    "question = \"How to do quota increase request?\"\n",
    "\n",
    "qa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25ca5565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the names of the embeddings models? \n",
      "\n",
      "Answer: The names of the embeddings models are:\n",
      "\n",
      "1. text-embedding-ada-002 (Version 2)\n",
      "2. DALL-E (Preview)\n",
      "3. Whisper (Preview)\n",
      "\n",
      "Thanks for asking! \n",
      "\n",
      "{\"source\": \"txt/faq.txt\"}\n"
     ]
    }
   ],
   "source": [
    "question = \"What are the names of the embeddings models?\"\n",
    "\n",
    "qa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "380ac033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How to update an index? \n",
      "\n",
      "Answer: You can update an index in Azure OpenAI on your data by scheduling an automatic index refresh or by uploading additional data to your Azure Blob Container and using it as your data source when you create a new index. The new index will include all of the data in your container. Thanks for asking! \n",
      "\n",
      "{\"source\": \"txt/faq.txt\"}\n"
     ]
    }
   ],
   "source": [
    "question = \"How to update an index?\"\n",
    "\n",
    "qa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1cf0e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the legacy models? \n",
      "\n",
      "Answer: The legacy models in Azure OpenAI Service are GPT-3.5 and GPT-3. These models are no longer available for new deployments starting from July 6, 2023. However, deployments created prior to that date will remain available until July 5, 2024. It is recommended to migrate to the replacement models, such as GPT-3.5 Turbo Instruct, before the retirement date. \n",
      "\n",
      "{\"source\": \"txt/faq.txt\"}\n"
     ]
    }
   ],
   "source": [
    "question = \"What are the legacy models?\"\n",
    "\n",
    "qa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "678499a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Can you tell me about GPT-3? \n",
      "\n",
      "Answer: Azure OpenAI Service offers GPT-3, which is a powerful language model developed by OpenAI. GPT-3 stands for \"Generative Pre-trained Transformer 3\" and it is designed to understand and generate natural language. It can be used for a wide range of applications such as text completion, language translation, question answering, and more. GPT-3 has been widely recognized for its ability to generate human-like text and has been used in various industries for different use cases. It is one of the models available in Azure OpenAI Service that customers can leverage for their language processing needs. Thanks for asking! \n",
      "\n",
      "{\"source\": \"txt/faq.txt\"}\n"
     ]
    }
   ],
   "source": [
    "question = \"Can you tell me about GPT-3?\"\n",
    "\n",
    "qa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5fa09e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the updates for Canada East region? \n",
      "\n",
      "Answer: The updates for the Canada East region in Azure OpenAI Service include:\n",
      "\n",
      "- Azure OpenAI is now available in the Canada East region.\n",
      "- Check the models page for the latest information on model availability in each region.\n",
      "\n",
      "Thanks for asking! \n",
      "\n",
      "{\"source\": \"txt/quotas-limits.txt\"}\n"
     ]
    }
   ],
   "source": [
    "question = \"What are the updates for Canada East region?\"\n",
    "\n",
    "qa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f119e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f558f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
