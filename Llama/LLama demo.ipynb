{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af47bb13",
   "metadata": {},
   "source": [
    "# LLama demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa75fcf",
   "metadata": {},
   "source": [
    "LlamaIndex ðŸ¦™ (GPT Index) is a project that provides a central interface to connect your large language models (LLMs) with external data. It allows you to index your data for various LLM tasks, such as text generation, summarization, question answering, etc., and remove concerns over prompt size limitations. It also supports data connectors to your common data sources and provides cost transparency and tools that reduce cost while increasing performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cdfe678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install openai --upgrade\n",
    "#%pip install langchain --upgrade\n",
    "#%pip install llama-index --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fbe299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import langchain\n",
    "import llama_index\n",
    "import nltk\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader, PromptHelper, LangchainEmbedding, ServiceContext\n",
    "from llama_index.llms import AzureOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd67301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open AI version: 0.27.9\n",
      "langchain version: 0.0.278\n",
      "llama_index version: 0.8.8\n"
     ]
    }
   ],
   "source": [
    "print('Open AI version:', openai.__version__)\n",
    "print('langchain version:', langchain.__version__)\n",
    "print('llama_index version:', llama_index.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbe67b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables (set OPENAI_API_KEY, OPENAI_API_BASE, and OPENAI_API_VERSION in .env)\n",
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "# Configure OpenAI API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv('OPENAI_API_BASE')\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_version = os.getenv('OPENAI_API_VERSION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58bedda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/langchain/embeddings/openai.py:214: UserWarning: WARNING! deployment_id is not default parameter.\n",
      "                    deployment_id was transferred to model_kwargs.\n",
      "                    Please confirm that deployment_id is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM and Embeddings model (model is the actual model name, e.g., gpt-35-turbo, engine is your custom deployment name, e.g., my-gpt-35-turbo)\n",
    "llm = AzureOpenAI(engine=\"gpt-35-turbo\", model=\"gpt-35-turbo\", temperature=0.0)\n",
    "embeddings = LangchainEmbedding(OpenAIEmbeddings(deployment_id=\"text-embedding-ada-002\", chunk_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29b23c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AzureOpenAI(callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7f39f4746650>, model='gpt-35-turbo', temperature=0, max_tokens=None, additional_kwargs={}, max_retries=10, engine='gpt-35-turbo')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0292fd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LangchainEmbedding(model_name='text-embedding-ada-002', embed_batch_size=10, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7f3a6c270640>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caf319f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt helper\n",
    "prompt_helper = PromptHelper(context_window=3000, \n",
    "                             num_output=500, \n",
    "                             chunk_overlap_ratio=0.1, \n",
    "                             chunk_size_limit=1000)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=embeddings, prompt_helper=prompt_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74659d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 6.6K Sep  5 09:15 docs/overview_clu.txt\r\n",
      "-rwxrwxrwx 1 root root 8.9K Sep  5 09:15 docs/overview_openai.txt\r\n",
      "-rwxrwxrwx 1 root root 3.6K Sep  5 09:15 docs/overview_translator.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls docs/*.* -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2876ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents\n",
    "documents = SimpleDirectoryReader('docs/').load_data()\n",
    "\n",
    "# Create index\n",
    "index = GPTVectorStoreIndex.from_documents(documents, service_context=service_context, prompt_helper=prompt_helper)\n",
    "query_engine = index.as_query_engine(service_context=service_context, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26b72a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is azure openai service? give me back a bullet point list\n",
      "\n",
      "Answer: - Azure OpenAI is a service that provides REST API access to OpenAI's language models including GPT-3, Codex, and Embeddings series.\n",
      "- The service offers several different models with varying capabilities and price points, including the GPT-3 base models Davinci, Curie, Babbage, and Ada, and the Codex series of models.\n",
      "- Users can access the service through REST APIs, Python SDK, or a web-based interface in the Azure OpenAI Studio.\n",
      "- The service provides a text-in, text-out interface where users can input a prompt and the model will generate a text completion.\n",
      "- Azure OpenAI has virtual network support and managed identity via Azure Active Directory.\n",
      "- The service is available in East US, South Central US, and West Europe regions.\n",
      "- Content filtering is in place to evaluate prompts and completions against a content policy with automated systems to filter high severity content.\n",
      "\n",
      "Sources: > Source (Doc id: b1d0d2a7-32f4-412b-9e6f-7eea1c8edad5): # What is Azure OpenAI?The Azure OpenAI service provides REST API access to OpenAI's powerful lan...\n",
      "\n",
      "> Source (Doc id: 462127c2-7b2a-4fc3-a894-591fed129b2d): ### Models\n",
      "\n",
      "The service provides users access to several different models.Each model provides a d...\n"
     ]
    }
   ],
   "source": [
    "query = \"What is azure openai service? give me back a bullet point list\"\n",
    "answer = query_engine.query(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print()\n",
    "print(f\"Answer: {answer}\")\n",
    "print()\n",
    "print(f\"Sources: {answer.get_formatted_sources()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e418e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
